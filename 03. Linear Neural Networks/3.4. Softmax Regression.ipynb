{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b315e5f0",
   "metadata": {},
   "source": [
    "# 3.4. Softmax Regression\n",
    "\n",
    "In Section 3.1, we introduced linear regression, working through implementations from scratch in Section 3.2 and again using high-level APIs of a deep learning framework in Section 3.3 to do the heavy lifting.\n",
    "\n",
    "Regression is the hammer we reach for when we want to answer how much? or how many? questions. If you want to predict the number of dollars (price) at which a house will be sold, or the number of wins a baseball team might have, or the number of days that a patient will remain hospitalized before being discharged, then you are probably looking for a regression model.\n",
    "\n",
    "In practice, we are more often interested in classification: asking not “how much” but “which one”:\n",
    "\n",
    "Does this email belong in the spam folder or the inbox?\n",
    "\n",
    "Is this customer more likely to sign up or not to sign up for a subscription service?\n",
    "\n",
    "Does this image depict a donkey, a dog, a cat, or a rooster?\n",
    "\n",
    "Which movie is Aston most likely to watch next?\n",
    "\n",
    "Colloquially, machine learning practitioners overload the word classification to describe two subtly different problems: (i) those where we are interested only in hard assignments of examples to categories (classes); and (ii) those where we wish to make soft assignments, i.e., to assess the probability that each category applies. The distinction tends to get blurred, in part, because often, even when we only care about hard assignments, we still use models that make soft assignments.\n",
    "\n",
    "## 3.4.1. Classification Problem\n",
    "## 3.4.2. Network Architecture\n",
    "## 3.4.3. Parameterization Cost of Fully-Connected Layers\n",
    "## 3.4.4. Softmax Operation\n",
    "## 3.4.5. Vectorization for Minibatches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb227e0",
   "metadata": {},
   "source": [
    "## 3.4.6. Loss Function\n",
    "\n",
    "Next, we need a loss function to measure the quality of our predicted probabilities. We will rely on maximum likelihood estimation, the very same concept that we encountered when providing a probabilistic justification for the mean squared error objective in linear regression (Section 3.1.3).\n",
    "\n",
    "### 3.4.6.1. Log-Likelihood\n",
    "### 3.4.6.2. Softmax and Derivatives\n",
    "### 3.4.6.3. Cross-Entropy Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8a9dc7",
   "metadata": {},
   "source": [
    "## 3.4.7. Information Theory Basics\n",
    "\n",
    "Information theory deals with the problem of encoding, decoding, transmitting, and manipulating information (also known as data) in as concise form as possible.\n",
    "\n",
    "### 3.4.7.1. Entropy\n",
    "### 3.4.7.2. Surprisal\n",
    "### 3.4.7.3. Cross-Entropy Revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3af014d",
   "metadata": {},
   "source": [
    "## 3.4.8. Model Prediction and Evaluation\n",
    "\n",
    "After training the softmax regression model, given any example features, we can predict the probability of each output class. Normally, we use the class with the highest predicted probability as the output class. The prediction is correct if it is consistent with the actual class (label). In the next part of the experiment, we will use accuracy to evaluate the model’s performance. This is equal to the ratio between the number of correct predictions and the total number of predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22dce12",
   "metadata": {},
   "source": [
    "## 3.4.9. Summary\n",
    "\n",
    "The softmax operation takes a vector and maps it into probabilities.\n",
    "\n",
    "Softmax regression applies to classification problems. It uses the probability distribution of the output class in the softmax operation.\n",
    "\n",
    "Cross-entropy is a good measure of the difference between two probability distributions. It measures the number of bits needed to encode the data given our model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
